---
author: "Ria Sharma"
output: html_document
title: Assignment 3
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message=FALSE, warning = FALSE,
                      fig.height = 3,
                      error = TRUE)
library(tidyverse)
source("../../scripts/viridis.R")
```

### Preliminaries

Code to read in data and source the *viridis.R* file assumes: (1) that you have the following directories and files, where COURSE is the path to your top course directory (it might be something like "~/Documents/stat240"); (2) that you have set the *hw03* directory to be your working directory; and (3) that you have installed both the **tidyverse** and **viridisLite** packages.

- Directories
    - COURSE/homework/
    - COURSE/homework/hw03/
    - COURSE/data/
    - COURSE/scripts/
- Files
    - COURSE/homework/hw03/hw03.Rmd
    - COURSE/data/madison-weather-official-1969-2023.csv
    - COURSE/data/exoplanets-clean-through-2022.csv
    - COURSE/scripts/viridis.R

#### Notes

- You will need to install the `viridisLite` package if you have not done so already.
- Code in the file `viridis.R` changes the default color scheme in `ggplot2` so that:
    - default colors are easier to perceive by people with a variety of color blindness conditions
    - when color is used to represent a continuous variable, perception of changes of shade are more even than in the default choice.
- Replace the text "YOUR NAME HERE" in the YAML section with your name.
- Edit this file, answer the questions, knit, and submit your solutions by uploading the resulting HTML file to the course Canvas site.  Be sure to review your HTML and ensure that your solutions appear as you expect prior to submitting.
- Post questions using Discord, visit the Learning Center, or attend office hours if you have questions.

### Aims

- Refine and expand **ggplot2** skills for making plots, including:
    - changing axis scales
    - using color and size
    - making bar plots for categorical data
    - breaking plots over multiple facets
- Demonstrate skills from **dplyr** for wrangling and summarizing data


### Problems

The following R chunk reads in the default exoplanet data,
selects some variables, and changes some variable names.
*Note: This data set is not the same as what you used in discussion this week. It has already been reduced to a file with one unique exoaplanet per row and variables have been selected and renamed.*

```{r read-planet-data}
## Read in the csv file
planets = read_csv("../../data/exoplanets-clean-through-2022.csv") 
```


  1. A small number of planets have both an estimated mass AND an estimated radius less than those of the Earth.  What are the names of these planets, what method(s) were used to detect them, and in what year were they discovered?

- Create a data summary table with the star name, planet name, method, year, mass, and radius of the planets that have **both** an estimated mass < 1 Earth mass **and** an estimated radius < 1 Earth radius.  
- Order the rows increasing by mass.
- Print the entire table.

```{r}
small_planets <- planets %>%
  filter(mass < 1, radius < 1) %>%
  arrange(mass) %>%
  select(planet, star, method, year, radius, mass)

print(small_planets)
```




  2. Using the exoplanet data table `planets`:

- filter so that you only use planets discovered by the radial velocity method;
- remove cases where either of the variables `year` or `mass` (or both) are missing;
- for this subset of exoplanets, create a table with a data summary with the number of planets discovered and the minimum mass of these planets by year
- print the first 10 rows and all columns of this data summary

Then, make a scatter plot of this data such that:

- the size of points are proportional to the number of planets discovered that year
- the y-axis is on the log10 scale *(hint:  consider `scale_y_continuous()` or `scale_y_log10()`)*
- the axes have descriptive labels, and
- the plot contains an informative title.

Note, a scatter plot where the size of the points is proportional to a numerical variable is called a *bubble plot*.

In addition to creating the graphic, respond to the question below the R chunk.

```{r}
filtered_planets <- planets %>%
  filter(method == "Radial Velocity", !is.na(year), !is.na(mass)) %>%
  group_by(year) %>%
  summarise(number_of_planets = n(),
            min_mass = min(mass))
print(filtered_planets %>% head(10))

ggplot(filtered_planets, aes(x = year, y = min_mass, size = number_of_planets)) +
  geom_point(alpha = 0.5) + 
  scale_y_log10() + 
  labs(x = "Year of Discovery",
       y = "Minimum Mass of Planets (log scale)",
       size = "Number of Planets Discovered",
       title = "Number of Planets Discovered by Year and Their Minimum Mass") +
  theme_minimal() +
  theme(legend.position = "bottom") 
```

**Describe the pattern between year and minimum mass of planet discovered using Radial Velocity.**

> Over time, the minimum mass of planets discovered using the Radial Velocity method is expected to decrease,reflecting technological advancements and improved detection methods, allowing astronomers to detect smaller, Earth-like planets that were previously undetectable. There is also an overall increase in discoveries over time, reflecting both the growing interest in exoplanet research and the continuous improvement in detection methods.


  3. Using the `planets` data set created at the beginning of the assignment
*(not the reduced data set from the previous problem)*,
determine which methods have been used to discover fewer than 30 planets each. For use in the remaining exoplanet problems,
create a subset of the data by:

- removing the planets discovered by those methods (with fewer than 30 exoplanet  discoveries)
    - *(Hint: Consider creating a column which contains for each case the total number of times that the corresponding method appears in the data set and then using this information inside of `filter()`.)*
    
> Print a summary table with the methods used at least 30 times and the total number of exoplanets discovered by each, arranged from highest to lowest.

- summarize *for each year*, the number of planets and the proportion of planets discovered by each method used 30 or more times. *(Note: filter to keep only methods that are used 30 or more times in the entire data set. Counts in a single year may be less.)*
  - proportions should sum to one within each year.
- arrange the rows by year in chronological order (earliest first)

This data summary should have one row for each year and method (if the method was used in that year) and columns with the names `year`, `method`, `n`, and `proportion`.
*(Hint: you may find it helpful also to create a `total` column with the total number of exoplanets discovered each year repeated for each row to help calculate the proportion.)*

```{r}
#subset
method_counts <- planets %>%
  group_by(method) %>%
  summarise(n = n()) %>%
  filter(n >= 30) 

filtered_planets <- planets %>%
  filter(method %in% method_counts$method)

method_summary <- filtered_planets %>%
  group_by(method) %>%
  summarise(total_discoveries = n()) %>%
  arrange(desc(total_discoveries))

print(method_summary)
#summary
yearly_totals <- filtered_planets %>%
  group_by(year) %>%
  summarise(yearly_total = n())

detailed_summary <- filtered_planets %>%
  left_join(yearly_totals, by = "year") %>%
  group_by(year, method) %>%
  summarise(n = n(),
            total = first(yearly_total)) %>%
  mutate(proportion = n / total) %>%
  arrange(year, desc(proportion))

print(detailed_summary)
```

Print the first 10 rows and all columns of this data summary.

```{r}
print(head(detailed_summary, 10))
```





  4. Using the data summary from the previous problem, create and display a bar plot with the year on the x axis and the proportion of discovered planets on the y axis.  Let each year have a single bar that extends from a proportion of 0 to 1, with sections of each bar filled with a color by method
Add appropriate axis labels and plot title.

```{r}
library(ggplot2)
ggplot(detailed_summary, aes(x = factor(year), y = proportion, fill = method)) +
  geom_bar(stat = "identity", position = "stack") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = "Year of Discovery",
       y = "Proportion of Planets Discovered",
       fill = "Method",
       title = "Proportion of Exoplanets Discovered by Year and Method") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
```


Which method was most successful with the earliest discoveries of exoplanets, and which method has supplanted that method in relative popularity in recent years?

> Initially, the Radial Velocity method was most successful in discovering exoplanets. This method measures variations in the speed with which a star moves toward or away from Earth, indicating the gravitational influence of an orbiting planet. In more recent years, the Transit method has likely supplanted Radial Velocity in relative popularity. This method detects exoplanets by observing the slight dimming of a star's light as an orbiting planet passes between the star and Earth.







  5. Begin with the data summary from the previous problem.

- filter to only include years from 2010 -- 2022 (include the endpoints of the range), and
- remove the rows corresponding to the "Transit" or "Radial Velocity" methods.

Using this modified data set, create a plot which:

- displays the *counts* of exoplanets discovered by method with a bar graph with year on the x axis, different fill colors for each method,
and the *counts* of the number of planets for each year and method on the y axis using the function `geom_col()`.
- does not stack the bars for each year, but rather display them next to each other in a clump by each year label.
(*Note: The default is to stack bars. Use the argument `position = position_dodge2(preserve = "single")` inside of `geom_col()` to avoid stacking and to preserve the same bar width when the number of methods present changes by year.*)
- adjusts the x-axis so a tick mark and label appears for each year (i.e., 2010, 2011, ..., 2022).  **(Hint: consider `scale_x_continuous()`.)**
- uses appropriate axis labels and plot title.

```{r}
filtered_data <- detailed_summary %>%
  filter(year >= 2010, year <= 2022, !method %in% c("Transit", "Radial Velocity"))
ggplot(filtered_data, aes(x = as.factor(year), y = n, fill = method)) +
  geom_col(position = position_dodge2(preserve = "single")) +
  scale_x_discrete(name = "Year of Discovery",
                   breaks = as.character(2010:2022),
                   labels = as.character(2010:2022)) +
  labs(y = "Count of Exoplanets Discovered",
       fill = "Method",
       title = "Count of Exoplanets Discovered by Year and Method (2010-2022)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```





```{r, include = FALSE}
official = read_csv("../../data/madison-weather-official-1869-2023.csv")
```

  6. Use the official Madison weather data. Find:

- **6a**. The dates with the five highest recorded maximum temperatures (there could be more than five dates due to ties)

```{r}
highest_temps <- official %>%
  arrange(desc(tmax)) %>%
  distinct(tmax, .keep_all = TRUE) %>%
  head(5)

print(highest_temps$date)
```



- **6b**. The proportion of all days by month with positive precipitation.

```{r}
positive_precipitation <- official %>%
  mutate(month = month(date, label = TRUE)) %>%
  group_by(month) %>%
  summarise(proportion_positive_precip = mean(prcp > 0, na.rm = TRUE))
print(positive_precipitation)
```



- **6c**. The average temperature (mean of `tavg`) by month for the years from 1991-2020. Consider these values to be the current *normal mean temperatures*. Then, find the average temperature by month in 2022. In how many months was the average temperature in 2022 higher than the normal mean temperature?

```{r}
normal_mean_temps <- official %>%
  filter(year(date) >= 1991, year(date) <= 2020) %>%
  mutate(month = month(date, label = TRUE)) %>%
  group_by(month) %>%
  summarise(normal_mean_temp = mean(tavg, na.rm = TRUE))

average_temp_2022 <- official %>%
  filter(year(date) == 2022) %>%
  mutate(month = month(date, label = TRUE)) %>%
  group_by(month) %>%
  summarise(avg_temp_2022 = mean(tavg, na.rm = TRUE))

comparison <- inner_join(normal_mean_temps, average_temp_2022, by = "month") %>%
  mutate(higher_in_2022 = avg_temp_2022 > normal_mean_temp)

print(sum(comparison$higher_in_2022))

```

> 7




- **6d**. The ten years with the highest average temperature on record since 1869. How many of these years have occurred since 2000?

```{r}
highest_avg_temps_years <- official %>%
  group_by(year = year(date)) %>%
  summarise(average_yearly_temp = mean(tavg, na.rm = TRUE)) %>%
  arrange(desc(average_yearly_temp)) %>%
  head(10)
print(highest_avg_temps_years)
years_since_2000 <- sum(highest_avg_temps_years$year >= 2000)
print(years_since_2000)

```




  7. The combined total monthly precipitation in Madison in 2023 was 0.95 inches in May and 1.14 inches in June.

- Calculate the total monthly precipitation for each May and for each June by year from the official daily Madison weather data from 1869--2023.
The resulting data set should have two rows for each of the years and columns for year, month, and total precipitation.
- Create a single summary data table with the 25 lowest precipitation months for May, from the years 1869--2023, ranked from smallest to largest. Add a leading column named `rank` with the values from 1 to 25 (don't worry about making the numbers right if there are ties).
    - This summary table should have columns `rank`, `year`, `month`, and the total precipiation in inches.

> Where did May 2023 rank among the driest Mays in recorded Madison history?

> Repeat for June. Where did June 2023 rank among the driest Junes in recorded Madison history?
  
  
```{r}
monthly_precip <- official %>%
  filter(month(date) %in% c(5, 6)) %>%
  group_by(year = year(date), month = month(date, label = TRUE)) %>%
  summarise(total_precipitation = sum(prcp, na.rm = TRUE)) %>%
  ungroup()

may_precip_summary <- monthly_precip %>%
  filter(month == "May") %>%
  arrange(total_precipitation) %>%
  mutate(rank = row_number()) %>%
  filter(rank <= 25)

print(may_precip_summary)
may_2023_rank <- filter(may_precip_summary, year == 2023)$rank
cat("Rank of May 2023 among the driest Mays:", may_2023_rank, "\n")

june_precip_summary <- monthly_precip %>%
  filter(month == "Jun") %>%
  arrange(total_precipitation) %>%
  mutate(rank = row_number()) %>%
  filter(rank <= 25)

print(june_precip_summary)
june_2023_rank <- filter(june_precip_summary, year == 2023)$rank
cat("Rank of June 2023 among the driest Junes:", june_2023_rank, "\n")
```

> 
Rank of May 2023 among the driest Mays: 6 
Rank of June 2023 among the driest Junes: 6 
  
  8. Return to the monthly total precipitation table for the months of May and June from 1869--2023. Create a new summary table by calculating the combined total for May and June within each year by summing the May and June totals.

- This summary table should have a column for `year` and a column for the combined total precipitation in May and June.

- Make a plot which shows the combined total precipitation in May and June in Madison from 1869--2023 versus the year. Add a smooth trend curve to the plot. Add a red dashed horizontal line at the combined total precipitation in May and June for 2023. Include meaningful axis labels and a title for the plot.
- Comment on how the combined precipitation in these two months in 2023 compares to the historical weather record.
  
```{r}
combined_precip <- official %>%
  filter(month(date) %in% c(5, 6)) %>%
  group_by(year = year(date)) %>%
  summarise(total_precip = sum(prcp, na.rm = TRUE))

ggplot(combined_precip, aes(x = year, y = total_precip)) +
  geom_line() + geom_point() + geom_smooth(method = "loess", se = FALSE, color = "blue") +  
  geom_hline(yintercept = combined_precip$total_precip[combined_precip$year == 2023], linetype = "dashed", color = "red") +
  labs(title = "Combined Total Precipitation in May and June (1869--2023)",
       x = "Year", y = "Total Precipitation (inches)") + theme_minimal()

```



